{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3 - Convolutional Neural Network\n",
    "\n",
    "This builds on examples 1 and 2 by creating a new, deeper architecture for the neural network. Instead of computing linear algebra directly in `numpy`, this example uses Theano's higher level abstractions to simplify the code and also obtain a speed boost (particularly on machines that have a compatible GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor import shared_randomstreams, tanh\n",
    "from theano.tensor.nnet import conv, softmax, sigmoid\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rc('font', family='Arial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Theano to use GPU. Delete and/or skip this block if you wish to use CPU instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    theano.config.device = 'gpu'\n",
    "except:\n",
    "    pass\n",
    "theano.config.floatX = 'float32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout_layer(layer, dropout_prob):\n",
    "    srng = shared_randomstreams.RandomStreams(\n",
    "        np.random.RandomState(0).randint(999999)\n",
    "    )\n",
    "    mask = srng.binomial(n=1, p=1-dropout_prob, size=layer.shape)\n",
    "    return layer * T.cast(mask, theano.config.floatX)\n",
    "\n",
    "def linear(z):\n",
    "    return z\n",
    "\n",
    "def load_data():\n",
    "    with gzip.open('./mnist.pkl.gz') as mnist_file:\n",
    "        data = pickle.load(mnist_file, encoding='bytes')\n",
    "    \n",
    "    def shared(data):\n",
    "        shared_x = theano.shared(\n",
    "            np.asarray(data[0], dtype=theano.config.floatX), borrow=True\n",
    "        )\n",
    "        shared_y = theano.shared(\n",
    "            np.asarray(data[1], dtype='int32'), borrow=True\n",
    "        )\n",
    "        return shared_x, shared_y\n",
    "\n",
    "    return shared(data[0]), shared(data[1]), shared(data[2])\n",
    "\n",
    "def one_hot(len_, j):\n",
    "    vec = np.zeros((len_, 1))\n",
    "    vec[j] = 1\n",
    "    return vec\n",
    "\n",
    "def relu(z):\n",
    "    return T.maximum(0, z)\n",
    "\n",
    "def size(data):\n",
    "    return data[0].get_value(borrow=True).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the various types of layers used in this deep network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvPoolLayer:\n",
    "    def __init__(self, filter_shape, image_shape, poolsize=(2,2),\n",
    "                 activation_fn=sigmoid):\n",
    "        self.filter_shape = filter_shape\n",
    "        self.image_shape = image_shape\n",
    "        self.poolsize = poolsize\n",
    "        self.activation_fn = activation_fn\n",
    "        \n",
    "        n_out = (\n",
    "            filter_shape[0] * \n",
    "            np.prod(filter_shape[2:]) / \n",
    "            np.prod(poolsize)\n",
    "        )\n",
    "        \n",
    "        self.weights = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(\n",
    "                    loc=0, \n",
    "                    scale=np.sqrt(1 / n_out),\n",
    "                    size=filter_shape\n",
    "                ),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "        self.biases = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(\n",
    "                    loc=0, \n",
    "                    scale=1,\n",
    "                    size=(filter_shape[0],)\n",
    "                ),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            borrow=True\n",
    "        )\n",
    "        \n",
    "        self.params = [self.weights, self.biases]\n",
    "\n",
    "    def set_input(self, input_, input_dropout, mini_batch_size):\n",
    "        self.input = input_.reshape(self.image_shape)\n",
    "        conv_out = conv.conv2d(\n",
    "            input=self.input,\n",
    "            filters=self.weights,\n",
    "            filter_shape=self.filter_shape,\n",
    "            image_shape=self.image_shape\n",
    "        )\n",
    "        pooled_out = downsample.max_pool_2d(\n",
    "            input=conv_out,\n",
    "            ds=self.poolsize,\n",
    "            ignore_border=True\n",
    "        )\n",
    "        self.output = self.activation_fn(\n",
    "            pooled_out + self.biases.dimshuffle('x', 0, 'x', 'x')\n",
    "        )\n",
    "        self.output_dropout = self.output\n",
    "        \n",
    "        \n",
    "\n",
    "class FullyConnectedLayer:\n",
    "    def __init__(self, n_in, n_out, activation_fn=sigmoid, dropout_prob=0):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.activation_fn = activation_fn\n",
    "        self.dropout_prob = dropout_prob\n",
    "        \n",
    "        self.weights = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(\n",
    "                    loc=0, scale=np.sqrt(1/n_out), size=(n_in, n_out)\n",
    "                ),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='weights', borrow=True\n",
    "        )\n",
    "        \n",
    "        self.biases = theano.shared(\n",
    "            np.asarray(\n",
    "                np.random.normal(loc=0, scale=1, size=(n_out,)),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='biases',\n",
    "            borrow=True\n",
    "        )\n",
    "        \n",
    "        self.params = [self.weights, self.biases]\n",
    "    \n",
    "    def set_input(self, input_, input_dropout, mini_batch_size):\n",
    "        self.input = input_.reshape((mini_batch_size, self.n_in))\n",
    "        self.output = self.activation_fn(\n",
    "            (1 - self.dropout_prob) * T.dot(self.input, self.weights) + \n",
    "            self.biases\n",
    "        )\n",
    "        self.y_out = T.argmax(self.output, axis=1)\n",
    "        self.input_dropout = dropout_layer(\n",
    "            input_dropout.reshape((mini_batch_size, self.n_in)),\n",
    "            self.dropout_prob\n",
    "        )\n",
    "        self.output_dropout = self.activation_fn(\n",
    "            T.dot(self.input_dropout, self.weights) + self.biases\n",
    "        )\n",
    "    \n",
    "    def accuracy(self, y):\n",
    "        return T.mean(T.eq(y, self.y_out))\n",
    "\n",
    "\n",
    "class SoftmaxLayer:\n",
    "    def __init__(self, n_in, n_out, dropout_prob=0):\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        self.weights = theano.shared(\n",
    "            np.zeros((n_in, n_out), dtype=theano.config.floatX),\n",
    "            name='weights',\n",
    "            borrow=True\n",
    "        )\n",
    "        \n",
    "        self.biases = theano.shared(\n",
    "            np.zeros((n_out,), dtype=theano.config.floatX),\n",
    "            name='biases',\n",
    "            borrow=True\n",
    "        )\n",
    "        \n",
    "        self.params = [self.weights, self.biases]\n",
    "    \n",
    "    def set_input(self, input_, input_dropout, mini_batch_size):\n",
    "        self.input = input_.reshape((mini_batch_size, self.n_in))\n",
    "        self.output = softmax(\n",
    "            (1 - self.dropout_prob) * T.dot(self.input, self.weights) +\n",
    "            self.biases\n",
    "        )\n",
    "        self.y_out = T.argmax(self.output, axis=1)\n",
    "        self.input_dropout = dropout_layer(\n",
    "            input_dropout.reshape((mini_batch_size, self.n_in)),\n",
    "            self.dropout_prob\n",
    "        )\n",
    "        self.output_dropout = softmax(\n",
    "            T.dot(self.input_dropout, self.weights) + self.biases\n",
    "        )\n",
    "    \n",
    "    def cost(self, net):\n",
    "        return -T.mean(\n",
    "            T.log(self.output_dropout)[T.arange(net.y.shape[0]), net.y]\n",
    "        )\n",
    "\n",
    "    def accuracy(self, y):\n",
    "        return T.mean(T.eq(y, self.y_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layers, mini_batch_size):\n",
    "        self.layers = layers\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.params = [p for layer in self.layers for p in layer.params]\n",
    "        self.x = T.matrix('x')\n",
    "        self.y = T.ivector('y')\n",
    "        self.layers[0].set_input(self.x, self.x, self.mini_batch_size)\n",
    "        \n",
    "        for l in range(1, len(self.layers)):\n",
    "            prev_layer = self.layers[l - 1]\n",
    "            layer = self.layers[l]\n",
    "            layer.set_input(\n",
    "                prev_layer.output, \n",
    "                prev_layer.output_dropout,\n",
    "                self.mini_batch_size\n",
    "            )\n",
    "        \n",
    "        self.output = self.layers[-1].output\n",
    "        self.output_dropout = self.layers[-1].output_dropout\n",
    "\n",
    "    def sgd(self, train_data, epochs, mini_batch_size, learning_rate,\n",
    "            eval_data, test_data, regularization=0):\n",
    "\n",
    "        train_x, train_y = train_data\n",
    "        validation_x, validation_y = validation_data\n",
    "        test_x, test_y = test_data\n",
    "        \n",
    "        num_train_batches = size(train_data) // mini_batch_size\n",
    "        num_validation_batches = size(validation_data) // mini_batch_size\n",
    "        num_test_batches = size(test_data) // mini_batch_size\n",
    "        \n",
    "        l2_norm_squared = sum((l.weights**2).sum() for l in self.layers)\n",
    "\n",
    "        cost = (\n",
    "            self.layers[-1].cost(self) + \n",
    "            0.5 * regularization * l2_norm_squared / num_train_batches\n",
    "        )\n",
    "        \n",
    "        grads = T.grad(cost, self.params)\n",
    "        updates = list()\n",
    "        \n",
    "        for param, grad in zip(self.params, grads):\n",
    "            updates.append((param, param - learning_rate * grad))\n",
    "            \n",
    "        i = T.lscalar()\n",
    "        mb = self.mini_batch_size\n",
    "\n",
    "        train_mb = theano.function(\n",
    "            [i],\n",
    "            cost,\n",
    "            updates=updates,\n",
    "            givens={\n",
    "                self.x: train_x[i * mb : (i+1) * mb],\n",
    "                self.y: train_y[i * mb : (i+1) * mb],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        validate_mb_accuracy = theano.function(\n",
    "            [i],\n",
    "            self.layers[-1].accuracy(self.y),\n",
    "            givens={\n",
    "                self.x: validation_x[i * mb : (i+1) * mb],\n",
    "                self.y: validation_y[i * mb : (i+1) * mb],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        test_mb_accuracy = theano.function(\n",
    "            [i],\n",
    "            self.layers[-1].accuracy(self.y),\n",
    "            givens={\n",
    "                self.x: test_x[i * mb : (i+1) * mb],\n",
    "                self.y: test_y[i * mb : (i+1) * mb],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.test_mb_predictions = theano.function(\n",
    "            [i],\n",
    "            self.layers[-1].y_out,\n",
    "            givens={\n",
    "                self.x: test_x[i * mb : (i+1) * mb],\n",
    "                self.y: test_y[i * mb : (i+1) * mb],\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        best_validation_accuracy = 0\n",
    "        best_iteration = 0\n",
    "        best_iter_test_accuracy = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for minibatch_index in range(num_train_batches):\n",
    "                iteration = num_train_batches * epoch + minibatch_index\n",
    "                if iteration % 1000 == 0:\n",
    "                    print('Training mini-batch #{}'.format(iteration))\n",
    "                cost_ij = train_mb(minibatch_index)\n",
    "                if (iteration + 1) % num_train_batches == 0:\n",
    "                    validation_accuracy = np.mean([\n",
    "                        validate_mb_accuracy(b) for b \n",
    "                        in range(num_validation_batches)\n",
    "                    ])\n",
    "                    print('Epoch {}: validation accuracy {:0.3f}%'\n",
    "                         .format(epoch, validation_accuracy))\n",
    "                    if validation_accuracy >= best_validation_accuracy:\n",
    "                        print(\"New best validation accuracy!\")\n",
    "                        best_validation_accuracy = validation_accuracy\n",
    "                        best_iteration = iteration\n",
    "                        if test_data:\n",
    "                            best_iter_test_accuracy = np.mean([\n",
    "                                test_mb_accuracy(b) for b\n",
    "                                in range(num_test_batches)\n",
    "                            ])\n",
    "                            print('Test accuracy is {:0.3f}'\n",
    "                                 .format(best_iter_test_accuracy))\n",
    "        \n",
    "        print('Finished training.')\n",
    "        print('Best validation accuracy was {:0.3f} at iteration={}'\n",
    "             .format(best_validation_accuracy, best_iteration))\n",
    "        print('Test accuracy was {:0.3f} in that iteration'\n",
    "             .format(best_iter_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MINI_BATCH_SIZE = 10\n",
    "\n",
    "net_layers = [\n",
    "    ConvPoolLayer(\n",
    "        image_shape=(MINI_BATCH_SIZE, 1, 28, 28),\n",
    "        filter_shape=(20, 1, 5, 5),\n",
    "        poolsize=(2, 2),\n",
    "        activation_fn=relu\n",
    "    ),\n",
    "    FullyConnectedLayer(n_in=20*12*12, n_out=100),\n",
    "    SoftmaxLayer(n_in=100, n_out=10)\n",
    "]\n",
    "\n",
    "net = Network(net_layers, mini_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mini-batch #0\n",
      "Training mini-batch #1000\n",
      "Training mini-batch #2000\n",
      "Training mini-batch #3000\n",
      "Training mini-batch #4000\n",
      "Epoch 0: validation accuracy 0.966\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.963\n",
      "Training mini-batch #5000\n",
      "Training mini-batch #6000\n",
      "Training mini-batch #7000\n",
      "Training mini-batch #8000\n",
      "Training mini-batch #9000\n",
      "Epoch 1: validation accuracy 0.978\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.977\n",
      "Training mini-batch #10000\n",
      "Training mini-batch #11000\n",
      "Training mini-batch #12000\n",
      "Training mini-batch #13000\n",
      "Training mini-batch #14000\n",
      "Epoch 2: validation accuracy 0.982\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.983\n",
      "Training mini-batch #15000\n",
      "Training mini-batch #16000\n",
      "Training mini-batch #17000\n",
      "Training mini-batch #18000\n",
      "Training mini-batch #19000\n",
      "Epoch 3: validation accuracy 0.984\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.984\n",
      "Training mini-batch #20000\n",
      "Training mini-batch #21000\n",
      "Training mini-batch #22000\n",
      "Training mini-batch #23000\n",
      "Training mini-batch #24000\n",
      "Epoch 4: validation accuracy 0.985\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.985\n",
      "Training mini-batch #25000\n",
      "Training mini-batch #26000\n",
      "Training mini-batch #27000\n",
      "Training mini-batch #28000\n",
      "Training mini-batch #29000\n",
      "Epoch 5: validation accuracy 0.986\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.985\n",
      "Training mini-batch #30000\n",
      "Training mini-batch #31000\n",
      "Training mini-batch #32000\n",
      "Training mini-batch #33000\n",
      "Training mini-batch #34000\n",
      "Epoch 6: validation accuracy 0.985\n",
      "Training mini-batch #35000\n",
      "Training mini-batch #36000\n",
      "Training mini-batch #37000\n",
      "Training mini-batch #38000\n",
      "Training mini-batch #39000\n",
      "Epoch 7: validation accuracy 0.986\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.986\n",
      "Training mini-batch #40000\n",
      "Training mini-batch #41000\n",
      "Training mini-batch #42000\n",
      "Training mini-batch #43000\n",
      "Training mini-batch #44000\n",
      "Epoch 8: validation accuracy 0.986\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.986\n",
      "Training mini-batch #45000\n",
      "Training mini-batch #46000\n",
      "Training mini-batch #47000\n",
      "Training mini-batch #48000\n",
      "Training mini-batch #49000\n",
      "Epoch 9: validation accuracy 0.986\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #50000\n",
      "Training mini-batch #51000\n",
      "Training mini-batch #52000\n",
      "Training mini-batch #53000\n",
      "Training mini-batch #54000\n",
      "Epoch 10: validation accuracy 0.986\n",
      "Training mini-batch #55000\n",
      "Training mini-batch #56000\n",
      "Training mini-batch #57000\n",
      "Training mini-batch #58000\n",
      "Training mini-batch #59000\n",
      "Epoch 11: validation accuracy 0.986\n",
      "Training mini-batch #60000\n",
      "Training mini-batch #61000\n",
      "Training mini-batch #62000\n",
      "Training mini-batch #63000\n",
      "Training mini-batch #64000\n",
      "Epoch 12: validation accuracy 0.987\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #65000\n",
      "Training mini-batch #66000\n",
      "Training mini-batch #67000\n",
      "Training mini-batch #68000\n",
      "Training mini-batch #69000\n",
      "Epoch 13: validation accuracy 0.987\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #70000\n",
      "Training mini-batch #71000\n",
      "Training mini-batch #72000\n",
      "Training mini-batch #73000\n",
      "Training mini-batch #74000\n",
      "Epoch 14: validation accuracy 0.987\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #75000\n",
      "Training mini-batch #76000\n",
      "Training mini-batch #77000\n",
      "Training mini-batch #78000\n",
      "Training mini-batch #79000\n",
      "Epoch 15: validation accuracy 0.987\n",
      "Training mini-batch #80000\n",
      "Training mini-batch #81000\n",
      "Training mini-batch #82000\n",
      "Training mini-batch #83000\n",
      "Training mini-batch #84000\n",
      "Epoch 16: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #85000\n",
      "Training mini-batch #86000\n",
      "Training mini-batch #87000\n",
      "Training mini-batch #88000\n",
      "Training mini-batch #89000\n",
      "Epoch 17: validation accuracy 0.988\n",
      "Training mini-batch #90000\n",
      "Training mini-batch #91000\n",
      "Training mini-batch #92000\n",
      "Training mini-batch #93000\n",
      "Training mini-batch #94000\n",
      "Epoch 18: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #95000\n",
      "Training mini-batch #96000\n",
      "Training mini-batch #97000\n",
      "Training mini-batch #98000\n",
      "Training mini-batch #99000\n",
      "Epoch 19: validation accuracy 0.988\n",
      "Training mini-batch #100000\n",
      "Training mini-batch #101000\n",
      "Training mini-batch #102000\n",
      "Training mini-batch #103000\n",
      "Training mini-batch #104000\n",
      "Epoch 20: validation accuracy 0.988\n",
      "Training mini-batch #105000\n",
      "Training mini-batch #106000\n",
      "Training mini-batch #107000\n",
      "Training mini-batch #108000\n",
      "Training mini-batch #109000\n",
      "Epoch 21: validation accuracy 0.988\n",
      "Training mini-batch #110000\n",
      "Training mini-batch #111000\n",
      "Training mini-batch #112000\n",
      "Training mini-batch #113000\n",
      "Training mini-batch #114000\n",
      "Epoch 22: validation accuracy 0.988\n",
      "Training mini-batch #115000\n",
      "Training mini-batch #116000\n",
      "Training mini-batch #117000\n",
      "Training mini-batch #118000\n",
      "Training mini-batch #119000\n",
      "Epoch 23: validation accuracy 0.988\n",
      "Training mini-batch #120000\n",
      "Training mini-batch #121000\n",
      "Training mini-batch #122000\n",
      "Training mini-batch #123000\n",
      "Training mini-batch #124000\n",
      "Epoch 24: validation accuracy 0.988\n",
      "Training mini-batch #125000\n",
      "Training mini-batch #126000\n",
      "Training mini-batch #127000\n",
      "Training mini-batch #128000\n",
      "Training mini-batch #129000\n",
      "Epoch 25: validation accuracy 0.988\n",
      "Training mini-batch #130000\n",
      "Training mini-batch #131000\n",
      "Training mini-batch #132000\n",
      "Training mini-batch #133000\n",
      "Training mini-batch #134000\n",
      "Epoch 26: validation accuracy 0.988\n",
      "Training mini-batch #135000\n",
      "Training mini-batch #136000\n",
      "Training mini-batch #137000\n",
      "Training mini-batch #138000\n",
      "Training mini-batch #139000\n",
      "Epoch 27: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #140000\n",
      "Training mini-batch #141000\n",
      "Training mini-batch #142000\n",
      "Training mini-batch #143000\n",
      "Training mini-batch #144000\n",
      "Epoch 28: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #145000\n",
      "Training mini-batch #146000\n",
      "Training mini-batch #147000\n",
      "Training mini-batch #148000\n",
      "Training mini-batch #149000\n",
      "Epoch 29: validation accuracy 0.988\n",
      "Training mini-batch #150000\n",
      "Training mini-batch #151000\n",
      "Training mini-batch #152000\n",
      "Training mini-batch #153000\n",
      "Training mini-batch #154000\n",
      "Epoch 30: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #155000\n",
      "Training mini-batch #156000\n",
      "Training mini-batch #157000\n",
      "Training mini-batch #158000\n",
      "Training mini-batch #159000\n",
      "Epoch 31: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #160000\n",
      "Training mini-batch #161000\n",
      "Training mini-batch #162000\n",
      "Training mini-batch #163000\n",
      "Training mini-batch #164000\n",
      "Epoch 32: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #165000\n",
      "Training mini-batch #166000\n",
      "Training mini-batch #167000\n",
      "Training mini-batch #168000\n",
      "Training mini-batch #169000\n",
      "Epoch 33: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #170000\n",
      "Training mini-batch #171000\n",
      "Training mini-batch #172000\n",
      "Training mini-batch #173000\n",
      "Training mini-batch #174000\n",
      "Epoch 34: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #175000\n",
      "Training mini-batch #176000\n",
      "Training mini-batch #177000\n",
      "Training mini-batch #178000\n",
      "Training mini-batch #179000\n",
      "Epoch 35: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #180000\n",
      "Training mini-batch #181000\n",
      "Training mini-batch #182000\n",
      "Training mini-batch #183000\n",
      "Training mini-batch #184000\n",
      "Epoch 36: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #185000\n",
      "Training mini-batch #186000\n",
      "Training mini-batch #187000\n",
      "Training mini-batch #188000\n",
      "Training mini-batch #189000\n",
      "Epoch 37: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.987\n",
      "Training mini-batch #190000\n",
      "Training mini-batch #191000\n",
      "Training mini-batch #192000\n",
      "Training mini-batch #193000\n",
      "Training mini-batch #194000\n",
      "Epoch 38: validation accuracy 0.988\n",
      "Training mini-batch #195000\n",
      "Training mini-batch #196000\n",
      "Training mini-batch #197000\n",
      "Training mini-batch #198000\n",
      "Training mini-batch #199000\n",
      "Epoch 39: validation accuracy 0.988\n",
      "Training mini-batch #200000\n",
      "Training mini-batch #201000\n",
      "Training mini-batch #202000\n",
      "Training mini-batch #203000\n",
      "Training mini-batch #204000\n",
      "Epoch 40: validation accuracy 0.988\n",
      "Training mini-batch #205000\n",
      "Training mini-batch #206000\n",
      "Training mini-batch #207000\n",
      "Training mini-batch #208000\n",
      "Training mini-batch #209000\n",
      "Epoch 41: validation accuracy 0.988\n",
      "Training mini-batch #210000\n",
      "Training mini-batch #211000\n",
      "Training mini-batch #212000\n",
      "Training mini-batch #213000\n",
      "Training mini-batch #214000\n",
      "Epoch 42: validation accuracy 0.988\n",
      "Training mini-batch #215000\n",
      "Training mini-batch #216000\n",
      "Training mini-batch #217000\n",
      "Training mini-batch #218000\n",
      "Training mini-batch #219000\n",
      "Epoch 43: validation accuracy 0.988\n",
      "Training mini-batch #220000\n",
      "Training mini-batch #221000\n",
      "Training mini-batch #222000\n",
      "Training mini-batch #223000\n",
      "Training mini-batch #224000\n",
      "Epoch 44: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #225000\n",
      "Training mini-batch #226000\n",
      "Training mini-batch #227000\n",
      "Training mini-batch #228000\n",
      "Training mini-batch #229000\n",
      "Epoch 45: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #230000\n",
      "Training mini-batch #231000\n",
      "Training mini-batch #232000\n",
      "Training mini-batch #233000\n",
      "Training mini-batch #234000\n",
      "Epoch 46: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #235000\n",
      "Training mini-batch #236000\n",
      "Training mini-batch #237000\n",
      "Training mini-batch #238000\n",
      "Training mini-batch #239000\n",
      "Epoch 47: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #240000\n",
      "Training mini-batch #241000\n",
      "Training mini-batch #242000\n",
      "Training mini-batch #243000\n",
      "Training mini-batch #244000\n",
      "Epoch 48: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #245000\n",
      "Training mini-batch #246000\n",
      "Training mini-batch #247000\n",
      "Training mini-batch #248000\n",
      "Training mini-batch #249000\n",
      "Epoch 49: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #250000\n",
      "Training mini-batch #251000\n",
      "Training mini-batch #252000\n",
      "Training mini-batch #253000\n",
      "Training mini-batch #254000\n",
      "Epoch 50: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #255000\n",
      "Training mini-batch #256000\n",
      "Training mini-batch #257000\n",
      "Training mini-batch #258000\n",
      "Training mini-batch #259000\n",
      "Epoch 51: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #260000\n",
      "Training mini-batch #261000\n",
      "Training mini-batch #262000\n",
      "Training mini-batch #263000\n",
      "Training mini-batch #264000\n",
      "Epoch 52: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #265000\n",
      "Training mini-batch #266000\n",
      "Training mini-batch #267000\n",
      "Training mini-batch #268000\n",
      "Training mini-batch #269000\n",
      "Epoch 53: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #270000\n",
      "Training mini-batch #271000\n",
      "Training mini-batch #272000\n",
      "Training mini-batch #273000\n",
      "Training mini-batch #274000\n",
      "Epoch 54: validation accuracy 0.988\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #275000\n",
      "Training mini-batch #276000\n",
      "Training mini-batch #277000\n",
      "Training mini-batch #278000\n",
      "Training mini-batch #279000\n",
      "Epoch 55: validation accuracy 0.989\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #280000\n",
      "Training mini-batch #281000\n",
      "Training mini-batch #282000\n",
      "Training mini-batch #283000\n",
      "Training mini-batch #284000\n",
      "Epoch 56: validation accuracy 0.989\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #285000\n",
      "Training mini-batch #286000\n",
      "Training mini-batch #287000\n",
      "Training mini-batch #288000\n",
      "Training mini-batch #289000\n",
      "Epoch 57: validation accuracy 0.989\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #290000\n",
      "Training mini-batch #291000\n",
      "Training mini-batch #292000\n",
      "Training mini-batch #293000\n",
      "Training mini-batch #294000\n",
      "Epoch 58: validation accuracy 0.989\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Training mini-batch #295000\n",
      "Training mini-batch #296000\n",
      "Training mini-batch #297000\n",
      "Training mini-batch #298000\n",
      "Training mini-batch #299000\n",
      "Epoch 59: validation accuracy 0.989\n",
      "New best validation accuracy!\n",
      "Test accuracy is 0.988\n",
      "Finished training.\n",
      "Best validation accuracy was 0.989 at iteration=299999\n",
      "Test accuracy was 0.988 in that iteration\n"
     ]
    }
   ],
   "source": [
    "net.sgd(\n",
    "    train_data,\n",
    "    epochs=60,\n",
    "    mini_batch_size=MINI_BATCH_SIZE,\n",
    "    learning_rate=0.1,\n",
    "    eval_data=validation_data,\n",
    "    test_data=test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show two random minibatches from the test set and the neural network's predicted labels. (Execute this cell again to pick a new set of random examples.) The actual label `y` and predicted label `Å·` are shown above each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAADbCAYAAABJJ6vAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fad3518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows, cols = 2, 5\n",
    "test_batches = size(test_data) //  MINI_BATCH_SIZE\n",
    "batch_num = random.randrange(0, test_batches)\n",
    "predictions = net.test_mb_predictions(batch_num)\n",
    "\n",
    "for i, y_hat in enumerate(predictions):\n",
    "    row = batch_num * MINI_BATCH_SIZE + i\n",
    "    x = test_data[0].get_value()[row]\n",
    "    y = test_data[1].get_value()[row]\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.reshape(x, (28,28)), cmap='Greys')\n",
    "    plt.title('y={}, Å·={}'.format(y, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
